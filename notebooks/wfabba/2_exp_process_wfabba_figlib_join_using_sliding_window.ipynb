{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e3d2ae",
   "metadata": {},
   "source": [
    "# Process WFABBA FIgLib Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642fba7",
   "metadata": {},
   "source": [
    "#### This notebook is different from the other notebook in that, this implements sliding window join to match goes observations with smokeynet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe6d26",
   "metadata": {},
   "source": [
    "<b>Summary:</b><br>\n",
    "Reads in parsed WFABBA data from csv files created from 1_process_wfabba_merge_files.ipynb (WFABBA GOES-16 & WFABBA GOES-17 detections), smokeynet_test.json & smokeynet_valid.json (SmokeyNet predictions), and camera_metadata_hpwren.csv (contains locations of camera stations associated with SmokeyNet predictions). Join SmokeyNet detections with camera metadata to associate coordinates with every SmokeyNet prediction. For every camera station, join SmokeyNet predictions with potential WFABBA GOES-16 and WFABBA GOES-17 detections, then output results to csv files.<br>\n",
    "\n",
    "- Read in parsed WFABBA data (outputted from 1_process_wfabba_merge_files.ipynb), SmokeyNet predictions, and camera metadata.\n",
    "- Join SmokeyNet predictions with potential WFABBA GOES-16/GOES-17 detections.\n",
    "- Output results to csv files\n",
    "\n",
    "<b>Output:</b><br>\n",
    "../..<br>\n",
    "└── data<br>\n",
    "&emsp;&emsp;&emsp;└── processed<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── \\<CAMERA_STATION_NAME\\>_all_hard_voting_35.csv<br>\n",
    "\n",
    "<b>Areas for Improvement:</b><br>\n",
    "Need to further look into approaches to join SmokeyNet detections with WFABBA GOES-16/GOES-17 detections. Currently looking at joining SmokeyNet predictions with WFABBA detections by location proximity distances (default of 35 miles), camera direction, and whether the detections happen at the exact minute. May need to look into temporal joins if going with current implementation of joins. \n",
    "If considering another join approach instead: Currently considering each image as an independent event. May need to consider groupings of images as an event instead. Consider finding first instance of SmokeyNet, WFABBA GOES-16, WFABBA GOES-17 detections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3db0f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import datetime as dt\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from haversine import haversine, Unit\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import pytz\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2eb2cc-feb2-4002-934a-3bc2e6b0946d",
   "metadata": {},
   "source": [
    "## 1) Read in WFABBA Data and Consolidate into WFABBA GOES-16/GOES-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dda350b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definte the processed and raw data directories\n",
    "processed_data_dir = \"../../data/processed/wfabba/\"\n",
    "raw_data_dir = \"../../data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a2af006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in GOES 16 inputs\n",
    "wfabba_goes_16_2019_df = pd.read_csv(processed_data_dir + \"GOES-16-2019.csv\")\n",
    "wfabba_goes_16_2020_df = pd.read_csv(processed_data_dir + \"GOES-16-2020.csv\")\n",
    "wfabba_goes_16_jan_2021_df = pd.read_csv(processed_data_dir + \"GOES-16-Jan-2021.csv\")\n",
    "wfabba_goes_16_2021_df = pd.read_csv(processed_data_dir + \"GOES-16-2021.csv\")\n",
    "wfabba_goes_16_2022_df = pd.read_csv(processed_data_dir + \"GOES-16-2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c5388068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unnecessary columns including ones which contain the same values or all NaN\n",
    "wfabba_goes_16_2019_df = wfabba_goes_16_2019_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_16_2020_df = wfabba_goes_16_2020_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_16_jan_2021_df = wfabba_goes_16_jan_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2021 detections\n",
    "wfabba_goes_16_2022_df = wfabba_goes_16_2022_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2022 detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ec0cc469-6a2b-4471-93f9-774ab88f5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93784\n",
      "92739\n"
     ]
    }
   ],
   "source": [
    "# filter out any January data in wfabba_goes_16_2021_df since it already exists in wfabba_goes_16_jan_2021_df\n",
    "print(len(wfabba_goes_16_2021_df))\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df[wfabba_goes_16_2021_df[\"Timestamp\"] >= \"2021-02-01\"]\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df.reset_index()\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df.drop(columns=[\"index\"])\n",
    "print(len(wfabba_goes_16_2021_df))\n",
    "# wfabba_goes_16_2021_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e5bbe8f8-1c99-4146-9afb-5915f315ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all GOES-16 dataframes into unified wfabba_goes_16_df\n",
    "wfabba_goes_16_df = pd.concat([wfabba_goes_16_2019_df, wfabba_goes_16_2020_df, wfabba_goes_16_jan_2021_df, wfabba_goes_16_2021_df, wfabba_goes_16_2022_df])\n",
    "wfabba_goes_16_df[\"timestamp_converted\"] = pd.to_datetime(wfabba_goes_16_df[\"Timestamp\"], infer_datetime_format=True, origin=\"unix\", utc=True)\n",
    "wfabba_goes_16_df = wfabba_goes_16_df.reset_index()\n",
    "wfabba_goes_16_df = wfabba_goes_16_df.drop(columns=[\"index\"])\n",
    "# wfabba_goes_16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "038112a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Satellite</th>\n",
       "      <th>FlightModel</th>\n",
       "      <th>ScanMode</th>\n",
       "      <th>ProductType</th>\n",
       "      <th>FileName</th>\n",
       "      <th>MissingValueCode</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Code</th>\n",
       "      <th>FRP</th>\n",
       "      <th>Fire Size</th>\n",
       "      <th>Fire Temp</th>\n",
       "      <th>Pixel Size</th>\n",
       "      <th>Obs BT4</th>\n",
       "      <th>Obs BT11</th>\n",
       "      <th>Bkg BT4</th>\n",
       "      <th>Bkg BT11</th>\n",
       "      <th>SolZen</th>\n",
       "      <th>SatZen</th>\n",
       "      <th>RelAzi</th>\n",
       "      <th>Eco</th>\n",
       "      <th>timestamp_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_5_012g</td>\n",
       "      <td>2019-06-01 00:06:41</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM1</td>\n",
       "      <td>C</td>\n",
       "      <td>FDCC</td>\n",
       "      <td>f2019152000641.rev.6_5_012g.FDCC.GOES-16</td>\n",
       "      <td>-9999</td>\n",
       "      <td>34.8046</td>\n",
       "      <td>-119.1102</td>\n",
       "      <td>15</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12645720</td>\n",
       "      <td>299.160</td>\n",
       "      <td>276.622</td>\n",
       "      <td>291.865</td>\n",
       "      <td>290.292</td>\n",
       "      <td>56.120</td>\n",
       "      <td>61.721</td>\n",
       "      <td>-9999</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-01 00:06:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_5_012g</td>\n",
       "      <td>2019-06-01 00:06:41</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM1</td>\n",
       "      <td>C</td>\n",
       "      <td>FDCC</td>\n",
       "      <td>f2019152000641.rev.6_5_012g.FDCC.GOES-16</td>\n",
       "      <td>-9999</td>\n",
       "      <td>33.8161</td>\n",
       "      <td>-116.9279</td>\n",
       "      <td>12</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>11221792</td>\n",
       "      <td>305.075</td>\n",
       "      <td>285.306</td>\n",
       "      <td>298.966</td>\n",
       "      <td>293.278</td>\n",
       "      <td>58.010</td>\n",
       "      <td>59.470</td>\n",
       "      <td>-9999</td>\n",
       "      <td>46</td>\n",
       "      <td>2019-06-01 00:06:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_5_012g</td>\n",
       "      <td>2019-06-01 00:10:44</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM1</td>\n",
       "      <td>F</td>\n",
       "      <td>FDCF</td>\n",
       "      <td>f2019152001044.rev.6_5_012g.FDCF.GOES-16</td>\n",
       "      <td>-9999</td>\n",
       "      <td>34.8046</td>\n",
       "      <td>-119.1102</td>\n",
       "      <td>15</td>\n",
       "      <td>56.4</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12645721</td>\n",
       "      <td>297.737</td>\n",
       "      <td>275.300</td>\n",
       "      <td>290.263</td>\n",
       "      <td>288.759</td>\n",
       "      <td>56.938</td>\n",
       "      <td>61.721</td>\n",
       "      <td>-9999</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-01 00:10:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_5_012g</td>\n",
       "      <td>2019-06-01 00:11:41</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM1</td>\n",
       "      <td>C</td>\n",
       "      <td>FDCC</td>\n",
       "      <td>f2019152001141.rev.6_5_012g.FDCC.GOES-16</td>\n",
       "      <td>-9999</td>\n",
       "      <td>34.8046</td>\n",
       "      <td>-119.1102</td>\n",
       "      <td>15</td>\n",
       "      <td>57.2</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12645720</td>\n",
       "      <td>297.646</td>\n",
       "      <td>275.515</td>\n",
       "      <td>290.003</td>\n",
       "      <td>288.553</td>\n",
       "      <td>57.143</td>\n",
       "      <td>61.721</td>\n",
       "      <td>-9999</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-01 00:11:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_5_012g</td>\n",
       "      <td>2019-06-01 00:16:41</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM1</td>\n",
       "      <td>C</td>\n",
       "      <td>FDCC</td>\n",
       "      <td>f2019152001641.rev.6_5_012g.FDCC.GOES-16</td>\n",
       "      <td>-9999</td>\n",
       "      <td>34.6392</td>\n",
       "      <td>-113.5781</td>\n",
       "      <td>15</td>\n",
       "      <td>35.1</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>10160281</td>\n",
       "      <td>308.435</td>\n",
       "      <td>297.187</td>\n",
       "      <td>305.010</td>\n",
       "      <td>302.197</td>\n",
       "      <td>62.694</td>\n",
       "      <td>57.443</td>\n",
       "      <td>-9999</td>\n",
       "      <td>51</td>\n",
       "      <td>2019-06-01 00:16:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314293</th>\n",
       "      <td>6_6_001g</td>\n",
       "      <td>2022-06-27 01:21:17</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM?</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>f2022178012117.rev.6_6_001g.FDCC.GOES-16.txt</td>\n",
       "      <td>-9999</td>\n",
       "      <td>34.7708</td>\n",
       "      <td>-116.3968</td>\n",
       "      <td>15</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>9141029</td>\n",
       "      <td>310.676</td>\n",
       "      <td>291.569</td>\n",
       "      <td>310.559</td>\n",
       "      <td>305.116</td>\n",
       "      <td>71.709</td>\n",
       "      <td>59.628</td>\n",
       "      <td>-9999</td>\n",
       "      <td>51</td>\n",
       "      <td>2022-06-27 01:21:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314294</th>\n",
       "      <td>6_6_001g</td>\n",
       "      <td>2022-06-27 01:26:17</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM?</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>f2022178012617.rev.6_6_001g.FDCC.GOES-16.txt</td>\n",
       "      <td>-9999</td>\n",
       "      <td>32.7308</td>\n",
       "      <td>-113.9479</td>\n",
       "      <td>15</td>\n",
       "      <td>20.1</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>8284628</td>\n",
       "      <td>308.972</td>\n",
       "      <td>291.042</td>\n",
       "      <td>307.019</td>\n",
       "      <td>299.238</td>\n",
       "      <td>75.255</td>\n",
       "      <td>56.520</td>\n",
       "      <td>-9999</td>\n",
       "      <td>37</td>\n",
       "      <td>2022-06-27 01:26:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314295</th>\n",
       "      <td>6_6_001g</td>\n",
       "      <td>2022-06-27 01:30:20</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM?</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>f2022178013020.rev.6_6_001g.FDCF.GOES-16.txt</td>\n",
       "      <td>-9999</td>\n",
       "      <td>32.7247</td>\n",
       "      <td>-114.6485</td>\n",
       "      <td>15</td>\n",
       "      <td>27.2</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>8420192</td>\n",
       "      <td>310.795</td>\n",
       "      <td>298.449</td>\n",
       "      <td>307.288</td>\n",
       "      <td>302.021</td>\n",
       "      <td>75.495</td>\n",
       "      <td>57.057</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-27 01:30:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314296</th>\n",
       "      <td>6_6_001g</td>\n",
       "      <td>2022-06-27 01:46:17</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM?</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>f2022178014617.rev.6_6_001g.FDCC.GOES-16.txt</td>\n",
       "      <td>-9999</td>\n",
       "      <td>32.7092</td>\n",
       "      <td>-113.5860</td>\n",
       "      <td>15</td>\n",
       "      <td>42.5</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>8211141</td>\n",
       "      <td>309.159</td>\n",
       "      <td>289.289</td>\n",
       "      <td>304.087</td>\n",
       "      <td>296.556</td>\n",
       "      <td>79.503</td>\n",
       "      <td>56.228</td>\n",
       "      <td>-9999</td>\n",
       "      <td>51</td>\n",
       "      <td>2022-06-27 01:46:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314297</th>\n",
       "      <td>6_6_001g</td>\n",
       "      <td>2022-06-27 02:26:17</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>FM?</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>GOES-16</td>\n",
       "      <td>f2022178022617.rev.6_6_001g.FDCC.GOES-16.txt</td>\n",
       "      <td>-9999</td>\n",
       "      <td>34.3368</td>\n",
       "      <td>-114.6777</td>\n",
       "      <td>15</td>\n",
       "      <td>28.5</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>8689150</td>\n",
       "      <td>306.498</td>\n",
       "      <td>289.004</td>\n",
       "      <td>302.373</td>\n",
       "      <td>298.338</td>\n",
       "      <td>85.679</td>\n",
       "      <td>58.069</td>\n",
       "      <td>-9999</td>\n",
       "      <td>51</td>\n",
       "      <td>2022-06-27 02:26:17+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314298 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Version            Timestamp Satellite FlightModel ScanMode  \\\n",
       "0       6_5_012g  2019-06-01 00:06:41   GOES-16         FM1        C   \n",
       "1       6_5_012g  2019-06-01 00:06:41   GOES-16         FM1        C   \n",
       "2       6_5_012g  2019-06-01 00:10:44   GOES-16         FM1        F   \n",
       "3       6_5_012g  2019-06-01 00:11:41   GOES-16         FM1        C   \n",
       "4       6_5_012g  2019-06-01 00:16:41   GOES-16         FM1        C   \n",
       "...          ...                  ...       ...         ...      ...   \n",
       "314293  6_6_001g  2022-06-27 01:21:17   GOES-16         FM?  GOES-16   \n",
       "314294  6_6_001g  2022-06-27 01:26:17   GOES-16         FM?  GOES-16   \n",
       "314295  6_6_001g  2022-06-27 01:30:20   GOES-16         FM?  GOES-16   \n",
       "314296  6_6_001g  2022-06-27 01:46:17   GOES-16         FM?  GOES-16   \n",
       "314297  6_6_001g  2022-06-27 02:26:17   GOES-16         FM?  GOES-16   \n",
       "\n",
       "       ProductType                                      FileName  \\\n",
       "0             FDCC      f2019152000641.rev.6_5_012g.FDCC.GOES-16   \n",
       "1             FDCC      f2019152000641.rev.6_5_012g.FDCC.GOES-16   \n",
       "2             FDCF      f2019152001044.rev.6_5_012g.FDCF.GOES-16   \n",
       "3             FDCC      f2019152001141.rev.6_5_012g.FDCC.GOES-16   \n",
       "4             FDCC      f2019152001641.rev.6_5_012g.FDCC.GOES-16   \n",
       "...            ...                                           ...   \n",
       "314293     GOES-16  f2022178012117.rev.6_6_001g.FDCC.GOES-16.txt   \n",
       "314294     GOES-16  f2022178012617.rev.6_6_001g.FDCC.GOES-16.txt   \n",
       "314295     GOES-16  f2022178013020.rev.6_6_001g.FDCF.GOES-16.txt   \n",
       "314296     GOES-16  f2022178014617.rev.6_6_001g.FDCC.GOES-16.txt   \n",
       "314297     GOES-16  f2022178022617.rev.6_6_001g.FDCC.GOES-16.txt   \n",
       "\n",
       "        MissingValueCode  Latitude  Longitude  Code   FRP  Fire Size  \\\n",
       "0                  -9999   34.8046  -119.1102    15  58.2    -9999.0   \n",
       "1                  -9999   33.8161  -116.9279    12  58.0    -9999.0   \n",
       "2                  -9999   34.8046  -119.1102    15  56.4    -9999.0   \n",
       "3                  -9999   34.8046  -119.1102    15  57.2    -9999.0   \n",
       "4                  -9999   34.6392  -113.5781    15  35.1    -9999.0   \n",
       "...                  ...       ...        ...   ...   ...        ...   \n",
       "314293             -9999   34.7708  -116.3968    15   7.2    -9999.0   \n",
       "314294             -9999   32.7308  -113.9479    15  20.1    -9999.0   \n",
       "314295             -9999   32.7247  -114.6485    15  27.2    -9999.0   \n",
       "314296             -9999   32.7092  -113.5860    15  42.5    -9999.0   \n",
       "314297             -9999   34.3368  -114.6777    15  28.5    -9999.0   \n",
       "\n",
       "        Fire Temp  Pixel Size  Obs BT4  Obs BT11  Bkg BT4  Bkg BT11  SolZen  \\\n",
       "0         -9999.0    12645720  299.160   276.622  291.865   290.292  56.120   \n",
       "1         -9999.0    11221792  305.075   285.306  298.966   293.278  58.010   \n",
       "2         -9999.0    12645721  297.737   275.300  290.263   288.759  56.938   \n",
       "3         -9999.0    12645720  297.646   275.515  290.003   288.553  57.143   \n",
       "4         -9999.0    10160281  308.435   297.187  305.010   302.197  62.694   \n",
       "...           ...         ...      ...       ...      ...       ...     ...   \n",
       "314293    -9999.0     9141029  310.676   291.569  310.559   305.116  71.709   \n",
       "314294    -9999.0     8284628  308.972   291.042  307.019   299.238  75.255   \n",
       "314295    -9999.0     8420192  310.795   298.449  307.288   302.021  75.495   \n",
       "314296    -9999.0     8211141  309.159   289.289  304.087   296.556  79.503   \n",
       "314297    -9999.0     8689150  306.498   289.004  302.373   298.338  85.679   \n",
       "\n",
       "        SatZen  RelAzi  Eco       timestamp_converted  \n",
       "0       61.721   -9999   22 2019-06-01 00:06:41+00:00  \n",
       "1       59.470   -9999   46 2019-06-01 00:06:41+00:00  \n",
       "2       61.721   -9999   22 2019-06-01 00:10:44+00:00  \n",
       "3       61.721   -9999   22 2019-06-01 00:11:41+00:00  \n",
       "4       57.443   -9999   51 2019-06-01 00:16:41+00:00  \n",
       "...        ...     ...  ...                       ...  \n",
       "314293  59.628   -9999   51 2022-06-27 01:21:17+00:00  \n",
       "314294  56.520   -9999   37 2022-06-27 01:26:17+00:00  \n",
       "314295  57.057   -9999    1 2022-06-27 01:30:20+00:00  \n",
       "314296  56.228   -9999   51 2022-06-27 01:46:17+00:00  \n",
       "314297  58.069   -9999   51 2022-06-27 02:26:17+00:00  \n",
       "\n",
       "[314298 rows x 24 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfabba_goes_16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a0b561d-14d9-4fa2-8d22-b27f9ff41840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in GOES 17 inputs\n",
    "wfabba_goes_17_2019_df = pd.read_csv(processed_data_dir + \"GOES-17-2019.csv\")\n",
    "wfabba_goes_17_2020_df = pd.read_csv(processed_data_dir + \"GOES-17-2020.csv\")\n",
    "wfabba_goes_17_jan_2021_df = pd.read_csv(processed_data_dir + \"GOES-17-Jan-2021.csv\")\n",
    "wfabba_goes_17_2021_df = pd.read_csv(processed_data_dir + \"GOES-17-2021.csv\")\n",
    "wfabba_goes_17_2022_df = pd.read_csv(processed_data_dir + \"GOES-17-2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3378d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of unnecessary columns including ones which contain the same values or all NaN\n",
    "wfabba_goes_17_2019_df = wfabba_goes_17_2019_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_17_2020_df = wfabba_goes_17_2020_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_17_jan_2021_df = wfabba_goes_17_jan_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2021 detections\n",
    "wfabba_goes_17_2022_df = wfabba_goes_17_2022_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2022 detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c6f774d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376689\n",
      "334881\n"
     ]
    }
   ],
   "source": [
    "# filter out any January data in wfabba_goes_17_2021_df since it already exists in wfabba_goes_17_jan_2021_df\n",
    "print(len(wfabba_goes_17_2021_df))\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df[wfabba_goes_17_2021_df[\"Timestamp\"] >= \"2021-02-01\"]\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df.reset_index()\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df.drop(columns=[\"index\"])\n",
    "print(len(wfabba_goes_17_2021_df))\n",
    "# wfabba_goes_17_2021_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7629ccdf-8dd1-4b21-b6ba-dd1cdfc29ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all GOES-17 dataframes into unified wfabba_goes_17_df\n",
    "wfabba_goes_17_df = pd.concat([wfabba_goes_17_2019_df, wfabba_goes_17_2020_df, wfabba_goes_17_jan_2021_df, wfabba_goes_17_2021_df, wfabba_goes_17_2022_df])\n",
    "wfabba_goes_17_df[\"timestamp_converted\"] = pd.to_datetime(wfabba_goes_17_df[\"Timestamp\"], infer_datetime_format=True, origin=\"unix\", utc=True)\n",
    "wfabba_goes_17_df = wfabba_goes_17_df.reset_index()\n",
    "wfabba_goes_17_df = wfabba_goes_17_df.drop(columns=[\"index\"])\n",
    "# wfabba_goes_17_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5233404",
   "metadata": {},
   "source": [
    "### Convert the coordinates of WFABBA GOES-17 and GOES-16 from EPSG 4326 to EPSG 3310 to allow for distance calculations down to the meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3d588d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert WFABBA GOES 16 coordinates from EPSG 4326 to EPSG 3310\n",
    "coords = [Point(xy) for xy in zip(wfabba_goes_16_df['Longitude'], wfabba_goes_16_df['Latitude'])]\n",
    "wfabba_goes_16_df = GeoDataFrame(wfabba_goes_16_df, crs = \"EPSG:4326\", geometry = coords) \n",
    "wfabba_goes_16_df = wfabba_goes_16_df.to_crs('EPSG:3310')\n",
    "# wfabba_goes_16_df[[\"Latitude\",\"Longitude\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "66170ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert WFABBA GOES 17 coordinates from EPSG 4326 to EPSG 3310\n",
    "coords = [Point(xy) for xy in zip(wfabba_goes_17_df['Longitude'], wfabba_goes_17_df['Latitude'])]\n",
    "wfabba_goes_17_df = GeoDataFrame(wfabba_goes_17_df, crs = \"EPSG:4326\", geometry = coords) \n",
    "wfabba_goes_17_df = wfabba_goes_17_df.to_crs('EPSG:3310')\n",
    "# wfabba_goes_17_df[[\"Latitude\",\"Longitude\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305deca",
   "metadata": {},
   "source": [
    "## 2) Camera Metadata Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "106ffbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in camera metadata\n",
    "camera_metadata_df = pd.read_csv(\"../../data/processed/camera_metadata_hpwren.csv\")\n",
    "# camera_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bb786ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in camera metadata\n",
    "camera_metadata_df = pd.read_csv(\"../../data/processed/camera_image_id_mappings.csv\")\n",
    "# camera_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9d530",
   "metadata": {},
   "source": [
    "## 3) Matching WFABBA to SmokeyNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8a7ea7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for every minute of specified time period\n",
    "times = []\n",
    "start = datetime(2019, 6 , 1, 0, 0, 0, 0, pytz.UTC)\n",
    "end = datetime(2021, 7, 11, 23, 59, 0, 0, pytz.UTC)\n",
    "\n",
    "while start <= end:\n",
    "    times.append(start)\n",
    "    start = start + timedelta(minutes = 1)\n",
    "\n",
    "minutes_df = pd.DataFrame(times, columns = [\"timestamp\"])\n",
    "# minutes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "73e75bb0-3df8-4ee8-9e92-9205f7bda59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing SmokeyNet df\n",
    "# df_test = pd.read_json(raw_data_dir + \"smokeynet_test.json\", orient=\"index\").reset_index().rename(columns={\"index\":\"filepath\"})\n",
    "header = ['index', 'image_pred', 'image_prob', 'image_loss']\n",
    "# df_test = pd.read_csv(\"../../data/raw/smokeynet_outputs/image_preds_test.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "df_test = pd.read_csv(\"../../data/raw/smokeynet_outputs/image_preds_test_new_split.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "# df_test = pd.read_csv(\"../../data/raw/smokeynet_outputs/test_paper_baseline_version4_last_model_image_preds.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "df_test[\"type\"] = \"test\"\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b733bfa-98ab-4ae9-9f31-b2f556cc0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create validating SmokeyNet df\n",
    "# df_valid = pd.read_json(raw_data_dir + \"smokeynet_valid.json\", orient=\"index\").reset_index().rename(columns={\"index\":\"filepath\"})\n",
    "header = ['index', 'image_pred', 'image_prob']\n",
    "# df_valid = pd.read_csv(\"../../data/raw/smokeynet_outputs/image_preds_valid.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "df_valid = pd.read_csv(\"../../data/raw/smokeynet_outputs/image_preds_val_new_split.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "# df_valid = pd.read_csv(\"../../data/raw/smokeynet_outputs/val_paper_baseline_version4_last_model_image_preds.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "df_valid[\"type\"] = \"valid\"\n",
    "# df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6310ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create validating SmokeyNet df\n",
    "# df_valid = pd.read_json(raw_data_dir + \"smokeynet_valid.json\", orient=\"index\").reset_index().rename(columns={\"index\":\"filepath\"})\n",
    "header = ['index', 'image_pred', 'image_prob']\n",
    "# df_valid = pd.read_csv(\"../../data/raw/smokeynet_outputs/image_preds_valid.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "df_train = pd.read_csv(\"../../data/raw/smokeynet_outputs/image_preds_train.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "# df_valid = pd.read_csv(\"../../data/raw/smokeynet_outputs/val_paper_baseline_version4_last_model_image_preds.csv\", names=header).rename(columns={\"index\":\"filepath\"})\n",
    "df_train[\"type\"] = \"train\"\n",
    "# df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dd790d2f-8e45-4f32-bd5c-3044e60abefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the SmokeyNet DFs together. For now just joining validation and test DFs\n",
    "# df_labels = pd.concat([df_test, df_valid]).reset_index().drop(columns = [\"index\"])\n",
    "df_labels = pd.concat([df_test, df_valid, df_train]).reset_index().drop(columns = [\"index\"])\n",
    "# df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "41058cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels['camera_name'] = df_labels.filepath.str.split(\"/\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c42e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_label(image_name):\n",
    "    \"\"\"Description: Returns 1 if image_name has a + in it (ie. is a positive) or 0 otherwise\"\"\"\n",
    "    ground_truth_label = 1 if \"+\" in image_name else 0\n",
    "    return ground_truth_label\n",
    "\n",
    "df_labels['image_gt'] = df_labels.filepath.apply(get_ground_truth_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "528957b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    11347\n",
       "valid     4894\n",
       "test      4798\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()\n",
    "df_labels.shape\n",
    "df_labels[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1385e849-0422-4511-bfa0-8fb9594ef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the date and year columns\n",
    "df_labels[\"date\"] = df_labels[\"camera_name\"].str.split(\"_\", n=1, expand=True)[0]\n",
    "df_labels[\"year\"] = df_labels[\"date\"].str[:4]\n",
    "df_labels[\"date\"] = pd.to_datetime(df_labels[\"date\"])\n",
    "# df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1652fb8f-6b19-4f7d-b382-116e7a59b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only entries from 2019-06-01 onwards\n",
    "# df_labels_filtered = df_labels[df_labels[\"date\"] >= \"2019-06-01\"].reset_index().drop(columns=[\"index\"])\n",
    "df_labels_filtered = df_labels.copy()\n",
    "# df_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e33523cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time, datetime, event_name, camera_name attributes\n",
    "df_labels_filtered[\"time\"] = df_labels_filtered[\"filepath\"].str.split(\"/\").str[1]\n",
    "df_labels_filtered[\"time\"] = df_labels_filtered[\"time\"].str.split(\"_\").str[0]\n",
    "df_labels_filtered[\"datetime\"] = pd.to_datetime(df_labels_filtered[\"time\"], unit=\"s\", origin=\"unix\", utc=True)\n",
    "df_labels_filtered[\"event_name\"] = df_labels_filtered[\"filepath\"].str.split(\"/\").str[0]\n",
    "df_labels_filtered[\"camera_name\"] = df_labels_filtered[\"camera_name\"].str.split(\"_\").str[-1]\n",
    "# df_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "079d7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join SmokeyNet data with camera metadata\n",
    "df_labels_filtered = df_labels_filtered.merge(camera_metadata_df, left_on=\"camera_name\", right_on=\"image_id\", how=\"left\")\n",
    "# df_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1421c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert joined SmokeyNet-camera metadata dataframe's coordinates from EPSG 4326 to EPSG 3310\n",
    "coords = [Point(xy) for xy in zip(df_labels_filtered['long'], df_labels_filtered['lat'])]\n",
    "df_labels_filtered = GeoDataFrame(df_labels_filtered, crs = \"EPSG:4326\", geometry = coords) \n",
    "df_labels_filtered = df_labels_filtered.to_crs('EPSG:3310')\n",
    "# df_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3693f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds timestamps to nearest minute on the dot\n",
    "def round_secs(x):\n",
    "    x = x + timedelta(minutes = 1)\n",
    "    x = x.replace(second=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4f4d380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if a WFABBA detection is within the same direction as the camera\n",
    "def is_in_camera_direction(camera_geometry_pt, direction, wfabba_geometry_pt):\n",
    "    if direction == \"north\":\n",
    "        # Has to be true for the image to be in front of the camera\n",
    "        return wfabba_geometry_pt.y >= camera_geometry_pt.y\n",
    "    elif direction == \"south\":\n",
    "        return wfabba_geometry_pt.y <= camera_geometry_pt.y\n",
    "    elif direction == \"east\":\n",
    "        return wfabba_geometry_pt.x >= camera_geometry_pt.x\n",
    "    elif direction == \"west\":\n",
    "        return wfabba_geometry_pt.x <= camera_geometry_pt.x\n",
    "    else:\n",
    "        # unknown or something else\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7dfc55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds any matches with specified WFABBA dataset based off of \n",
    "# whether distance to camera is within specified radius & camera direction\n",
    "def matches_distance_prox(camera_geometry, direction, radius_miles, wfabba_df):    \n",
    "    wfabba_df[\"distance_m\"] = wfabba_df[\"geometry\"].distance(camera_geometry)\n",
    "    wfabba_df[\"distance_mi\"] = wfabba_df[\"distance_m\"]/1609.344        \n",
    "    match_results_df = wfabba_df[(wfabba_df[\"distance_mi\"] <= radius_miles)].copy()\n",
    "    \n",
    "    #filter for detections within same direction\n",
    "    match_results_df[\"is_in_direction\"] = match_results_df.apply(\n",
    "        lambda row: is_in_camera_direction(camera_geometry, direction, row[\"geometry\"]), axis=1\n",
    "    )\n",
    "    match_results_df = match_results_df[match_results_df[\"is_in_direction\"] == True]\n",
    "\n",
    "    return match_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5444eefc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# round the SmokeyNet timestamps to nearest minute on the dot\n",
    "df_labels_filtered[\"datetime_rounded\"] = df_labels_filtered[\"datetime\"].apply(lambda x: round_secs(x))\n",
    "# df_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "59155c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all unique cameras being considered\n",
    "unique_cameras = df_labels_filtered[\"camera_name\"].unique()\n",
    "# unique_cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3f7731c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['69bravo-e-mobo-c', 'bh-n-mobo-c', 'bh-s-mobo-c', 'bh-w-mobo-c',\n",
       "       'bl-e-mobo-c', 'bl-n-mobo-c', 'bl-s-mobo-c', 'bm-e-mobo-c',\n",
       "       'bm-n-mobo-c', 'bm-s-mobo-c', 'bm-w-mobo-c', 'cp-s-mobo-c',\n",
       "       'dwpgm-n-mobo-c', 'hp-e-mobo-c', 'hp-n-mobo-c', 'hp-s-mobo-c',\n",
       "       'hp-w-mobo-c', 'lo-s-mobo-c', 'lo-w-mobo-c', 'lp-e-mobo-c',\n",
       "       'lp-n-mobo', 'lp-n-mobo-c', 'lp-s-mobo', 'lp-s-mobo-c',\n",
       "       'lp-w-mobo-c', 'marconi-n-mobo-c', 'mg-n-mobo-c', 'mg-s-mobo-c',\n",
       "       'mg-w-mobo-c', 'ml-n-mobo-c', 'ml-s-mobo-c', 'ml-w-mobo-c',\n",
       "       'mlo-e-mobo-c', 'mlo-n-mobo-c', 'mlo-s-mobo-c', 'om-e-mobo-c',\n",
       "       'om-n-mobo', 'om-n-mobo-c', 'om-s-mobo', 'om-s-mobo-c',\n",
       "       'om-w-mobo', 'om-w-mobo-c', 'pi-e-mobo-c', 'pi-n-mobo-c',\n",
       "       'pi-s-mobo', 'pi-s-mobo-c', 'pi-w-mobo-c', 'rm-e-mobo-c',\n",
       "       'rm-n-mobo-c', 'rm-w-mobo-c', 'sclm-e-mobo-c', 'sdsc-e-mobo-c',\n",
       "       'sjh-n-mobo-c', 'sm-e-mobo-c', 'sm-n-mobo-c', 'sm-s-mobo-c',\n",
       "       'sm-w-mobo-c', 'smer-tcs10-mobo-c', 'smer-tcs3-mobo-c',\n",
       "       'smer-tcs8-mobo-c', 'smer-tcs9-mobo-c', 'so-n-mobo-c',\n",
       "       'so-s-mobo-c', 'so-w-mobo-c', 'sp-e-mobo-c', 'sp-n-mobo-c',\n",
       "       'sp-s-mobo-c', 'sp-w-mobo-c', 'syp-n-mobo-c', 'syp-w-mobo-c',\n",
       "       'tp-e-mobo-c', 'tp-s-mobo-c', 'tp-w-mobo-c', 'vo-n-mobo-c',\n",
       "       'vo-w-mobo-c', 'wc-e-mobo-c', 'wc-n-mobo-c', 'wc-s-mobo-c'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if there are cameras that don't have associated directions, filter them out\n",
    "unusable_cameras = df_labels_filtered[df_labels_filtered[\"direction\"].isna()][\"camera_name\"].unique()\n",
    "unique_cameras = np.setdiff1d(unique_cameras, unusable_cameras)\n",
    "unique_cameras "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24252fd8",
   "metadata": {},
   "source": [
    "### Join smokeynet preds, goes16 and goes17 (direct join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbbd4414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [16:33<00:00, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores_arr = []\n",
    "csv_suffix = \"_all_hard_voting_35.csv\"\n",
    "\n",
    "# spatial radius of potential WFABBA matches\n",
    "distance_miles = 35\n",
    "# distance_miles = 80\n",
    "\n",
    "#looping for each camera station\n",
    "for camera in tqdm(unique_cameras):\n",
    "    \n",
    "    # print(\"Camera:\",camera)\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    \n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #Find GOES-17 matches\n",
    "    goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "    goes_17_dist_match_df[\"timestamp_converted_rounded\"] = goes_17_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_17_dist_match_df = goes_17_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #SmokeyNet_join\n",
    "    test_df = minutes_df.merge(camera_df, left_on = \"timestamp\", right_on = \"datetime_rounded\",how=\"left\")\n",
    "    test_df = test_df.rename(columns = {\"geometry\":\"HPWREN_Station_geometry\", \"lat\":\"HPWREN_lat\", \"long\":\"HPWREN_long\", \"datetime_rounded\":\"SmokeyNet_datetime_rounded\"})\n",
    "    # print(\"joined SmokeyNet\")\n",
    "\n",
    "    select_goes_cols = [\"timestamp_converted_rounded\", \"geometry\", \"Code\", \"FRP\", \"Fire Temp\", \n",
    "                                    \"Pixel Size\", \"Obs BT4\", \"Obs BT11\", \"Bkg BT4\", \"Bkg BT11\"]\n",
    "    \n",
    "    #GOES-16 Join\n",
    "    test_df = test_df.merge(goes_16_dist_match_df[select_goes_cols], left_on = \"timestamp\", right_on = \"timestamp_converted_rounded\",how=\"left\")\n",
    "    renamed_col_dict = {x:\"WFABBA_GOES16_\"+x.replace(\" \", \"_\") for x in select_goes_cols}\n",
    "    test_df = test_df.rename(columns = renamed_col_dict)\n",
    "    test_df = test_df[[\"timestamp\",\"camera_name\", \"image_gt\", \"image_pred\", \"image_prob\", \"type\"] + list(renamed_col_dict.values())]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] != None,'goes16_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] == None,'goes16_pred'] = 0\n",
    "    # print(\"joined GOES16\")\n",
    "\n",
    "    #GOES-17 Join\n",
    "    old_columns = test_df.columns.to_list()\n",
    "    test_df = test_df.merge(goes_17_dist_match_df[select_goes_cols], left_on = \"timestamp\", right_on = \"timestamp_converted_rounded\",how=\"left\")\n",
    "    renamed_col_dict = {x:\"WFABBA_GOES17_\"+x.replace(\" \", \"_\") for x in select_goes_cols}\n",
    "    test_df = test_df.rename(columns = renamed_col_dict)\n",
    "    test_df = test_df[old_columns + list(renamed_col_dict.values())]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] != None,'goes17_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] == None,'goes17_pred'] = 0\n",
    "    # print(\"joined GOES17\")\n",
    "\n",
    "    #Get all votes and determine if smoke was detected by majority rule\n",
    "    test_df[\"final_vote\"] = test_df[\"image_pred\"] + test_df[\"goes16_pred\"] + test_df[\"goes17_pred\"]\n",
    "    test_df.loc[test_df[\"final_vote\"] >= 2,'final_pred'] = 1\n",
    "    test_df.loc[test_df[\"final_vote\"] < 2,'final_pred'] = 0\n",
    "\n",
    "    image_labels = test_df[~test_df[\"image_gt\"].isna()][\"image_gt\"]\n",
    "    smokeynet_preds = test_df[~test_df[\"image_gt\"].isna()][\"image_pred\"]\n",
    "    ensemble_preds = test_df[~test_df[\"image_gt\"].isna()][\"final_pred\"]\n",
    "\n",
    "    baseline_score = accuracy_score(image_labels, smokeynet_preds)\n",
    "    ensemble_score = accuracy_score(image_labels, ensemble_preds)\n",
    "    scores_arr.append([camera, baseline_score, ensemble_score])\n",
    "    \n",
    "    # print(\"Baseline score:\", baseline_score)\n",
    "    # print(\"Ensemble score:\", ensemble_score)\n",
    "    test_df[~test_df[\"image_gt\"].isna()]\\\n",
    "        .to_csv(processed_data_dir + camera + csv_suffix)\n",
    "    # print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = PrettyTable([\"Camera\", \"Baseline Acc\", \"Ensemble Acc\"])\n",
    "output_table.add_rows(scores_arr[-55:])\n",
    "output_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e859b9",
   "metadata": {},
   "source": [
    "## Join smokeynet, goes16, goes17 based on sliding window join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fda97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "346e3bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [18:53<00:00, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_suffix = \"_all_hard_voting_35.csv\"\n",
    "sliding_window_data_dir = '../../data/processed/wfabba_sliding_time_offset_120/'\n",
    "time_offset = 120\n",
    "# os.system(f\"mkdir -p {sliding_window_data_dir}\")\n",
    "\n",
    "# spatial radius of potential WFABBA matches\n",
    "distance_miles = 35\n",
    "# distance_miles = 80\n",
    "\n",
    "for camera in tqdm(unique_cameras):\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    \n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #Find GOES-17 matches\n",
    "    goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "    goes_17_dist_match_df[\"timestamp_converted_rounded\"] = goes_17_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_17_dist_match_df = goes_17_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    camera_df.sort_values(by=['event_name', 'datetime_rounded'], inplace=True)\n",
    "    goes_16_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "    goes_17_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "\n",
    "    #SmokeyNet_join\n",
    "    test_df = minutes_df.merge(camera_df, left_on = \"timestamp\", right_on = \"datetime_rounded\", how = \"left\")\n",
    "    test_df = test_df.rename(columns = {\"geometry\":\"HPWREN_Station_geometry\", \"lat\":\"HPWREN_lat\", \"long\":\"HPWREN_long\", \"datetime_rounded\":\"SmokeyNet_datetime_rounded\"})\n",
    "    # print(\"joined SmokeyNet\")\n",
    "\n",
    "    select_goes_cols = [\"timestamp_converted_rounded\", \"geometry\", \"Code\", \"FRP\", \"Fire Temp\", \n",
    "                                    \"Pixel Size\", \"Obs BT4\", \"Obs BT11\", \"Bkg BT4\", \"Bkg BT11\"]\n",
    "    \n",
    "    #GOES-16 Join\n",
    "    test_df = pd.merge_asof(\n",
    "        left=test_df,\n",
    "        right=goes_16_dist_match_df[select_goes_cols],\n",
    "        left_on='timestamp',\n",
    "        right_on='timestamp_converted_rounded',\n",
    "        tolerance=pd.Timedelta(minutes=time_offset),\n",
    "        direction='forward'\n",
    "    )\n",
    "    renamed_col_dict = {x:\"WFABBA_GOES16_\"+x.replace(\" \", \"_\") for x in select_goes_cols}\n",
    "    test_df = test_df.rename(columns = renamed_col_dict)\n",
    "    test_df = test_df[[\"timestamp\",\"camera_name\", \"image_gt\", \"image_pred\", \"image_prob\", \"type\"] + list(renamed_col_dict.values())]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] != None,'goes16_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] == None,'goes16_pred'] = 0\n",
    "    # print(\"joined GOES16\")\n",
    "\n",
    "    #GOES-17 Join\n",
    "    old_columns = test_df.columns.to_list()\n",
    "    test_df = pd.merge_asof(\n",
    "        left=test_df,\n",
    "        right=goes_17_dist_match_df[select_goes_cols],\n",
    "        left_on='timestamp',\n",
    "        right_on='timestamp_converted_rounded',\n",
    "        tolerance=pd.Timedelta(minutes=time_offset),\n",
    "        direction='forward'\n",
    "    )\n",
    "    renamed_col_dict = {x:\"WFABBA_GOES17_\"+x.replace(\" \", \"_\") for x in select_goes_cols}\n",
    "    test_df = test_df.rename(columns = renamed_col_dict)\n",
    "    test_df = test_df[old_columns + list(renamed_col_dict.values())]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] != None,'goes17_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] == None,'goes17_pred'] = 0\n",
    "    # print(\"joined GOES17\")\n",
    "\n",
    "    #Get all votes and determine if smoke was detected by majority rule\n",
    "    test_df[\"final_vote\"] = test_df[\"image_pred\"] + test_df[\"goes16_pred\"] + test_df[\"goes17_pred\"]\n",
    "    test_df.loc[test_df[\"final_vote\"] >= 2,'final_pred'] = 1\n",
    "    test_df.loc[test_df[\"final_vote\"] < 2,'final_pred'] = 0\n",
    "\n",
    "    image_labels = test_df[~test_df[\"image_gt\"].isna()][\"image_gt\"]\n",
    "    smokeynet_preds = test_df[~test_df[\"image_gt\"].isna()][\"image_pred\"]\n",
    "    ensemble_preds = test_df[~test_df[\"image_gt\"].isna()][\"final_pred\"]\n",
    "\n",
    "    baseline_score = accuracy_score(image_labels, smokeynet_preds)\n",
    "    ensemble_score = accuracy_score(image_labels, ensemble_preds)\n",
    "    scores_arr.append([camera, baseline_score, ensemble_score])\n",
    "    \n",
    "    # print(\"Baseline score:\", baseline_score)\n",
    "    # print(\"Ensemble score:\", ensemble_score)\n",
    "    test_df[~test_df[\"image_gt\"].isna()] \\\n",
    "        .to_csv(sliding_window_data_dir + camera + csv_suffix)\n",
    "    # print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = PrettyTable([\"Camera\", \"Baseline Acc\", \"Ensemble Acc\"])\n",
    "output_table.add_rows(scores_arr[-55:])\n",
    "output_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6283a",
   "metadata": {},
   "source": [
    "### Sliding Window: join based on nearest time observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "992a7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1291ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "csv_suffix = \"_all_hard_voting_train_too_35_window_20.csv\"\n",
    "sliding_window_data_dir = '../../data/processed/wfabba_sliding_window_new_split/'\n",
    "# sliding_window_data_dir = '../../data/processed/wfabba_sliding_window_nearest_without_code_15/'\n",
    "\n",
    "# spatial radius of potential WFABBA matches\n",
    "distance_miles = 35\n",
    "time_offset = 20\n",
    "# distance_miles = 80\n",
    "\n",
    "for camera in tqdm(unique_cameras):\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    \n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #Find GOES-17 matches\n",
    "    goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "    goes_17_dist_match_df[\"timestamp_converted_rounded\"] = goes_17_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_17_dist_match_df = goes_17_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    camera_df.sort_values(by=['event_name', 'datetime_rounded'], inplace=True)\n",
    "    goes_16_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "    goes_17_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "\n",
    "    #SmokeyNet_join\n",
    "    test_df = minutes_df.merge(camera_df, left_on = \"timestamp\", right_on = \"datetime_rounded\", how = \"left\")\n",
    "    test_df = test_df.rename(columns = {\"geometry\":\"HPWREN_Station_geometry\", \"lat\":\"HPWREN_lat\", \"long\":\"HPWREN_long\", \"datetime_rounded\":\"SmokeyNet_datetime_rounded\"})\n",
    "    # print(\"joined SmokeyNet\")\n",
    "    \n",
    "    select_goes_cols = [\"timestamp_converted_rounded\", \"geometry\", \"Code\", \"FRP\", \"Fire Temp\", \n",
    "                                    \"Pixel Size\", \"Obs BT4\", \"Obs BT11\", \"Bkg BT4\", \"Bkg BT11\"]\n",
    "\n",
    "    #GOES-16 Join\n",
    "    test_df = pd.merge_asof(\n",
    "        left=test_df,\n",
    "        right=goes_16_dist_match_df[select_goes_cols],\n",
    "        left_on='timestamp',\n",
    "        right_on='timestamp_converted_rounded',\n",
    "        tolerance=pd.Timedelta(minutes=time_offset),\n",
    "        direction='nearest'\n",
    "    )\n",
    "    renamed_col_dict = {x:\"WFABBA_GOES16_\"+x.replace(\" \", \"_\") for x in select_goes_cols}\n",
    "    test_df = test_df.rename(columns = renamed_col_dict)\n",
    "    test_df = test_df[[\"timestamp\",\"camera_name\", \"image_gt\", \"image_pred\", \"image_prob\", \"type\", \"event_name\", \"filepath\"] + list(renamed_col_dict.values())]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] != None,'goes16_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] == None,'goes16_pred'] = 0\n",
    "    # print(\"joined GOES16\")\n",
    "\n",
    "    #GOES-17 Join\n",
    "    old_columns = test_df.columns.to_list()\n",
    "    test_df = pd.merge_asof(\n",
    "        left=test_df,\n",
    "        right=goes_17_dist_match_df[select_goes_cols],\n",
    "        left_on='timestamp',\n",
    "        right_on='timestamp_converted_rounded',\n",
    "        tolerance=pd.Timedelta(minutes=time_offset),\n",
    "        direction='nearest'\n",
    "    )\n",
    "    renamed_col_dict = {x:\"WFABBA_GOES17_\"+x.replace(\" \", \"_\") for x in select_goes_cols}\n",
    "    test_df = test_df.rename(columns = renamed_col_dict)\n",
    "    test_df = test_df[old_columns + list(renamed_col_dict.values())]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] != None,'goes17_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] == None,'goes17_pred'] = 0\n",
    "    # print(\"joined GOES17\")\n",
    "\n",
    "    #Get all votes and determine if smoke was detected by majority rule\n",
    "    test_df[\"final_vote\"] = test_df[\"image_pred\"] + test_df[\"goes16_pred\"] + test_df[\"goes17_pred\"]\n",
    "    test_df.loc[test_df[\"final_vote\"] >= 2,'final_pred'] = 1\n",
    "    test_df.loc[test_df[\"final_vote\"] < 2,'final_pred'] = 0\n",
    "\n",
    "    image_labels = test_df[~test_df[\"image_gt\"].isna()][\"image_gt\"]\n",
    "    smokeynet_preds = test_df[~test_df[\"image_gt\"].isna()][\"image_pred\"]\n",
    "    ensemble_preds = test_df[~test_df[\"image_gt\"].isna()][\"final_pred\"]\n",
    "\n",
    "    baseline_score = accuracy_score(image_labels, smokeynet_preds)\n",
    "    ensemble_score = accuracy_score(image_labels, ensemble_preds)\n",
    "    scores_arr.append([camera, baseline_score, ensemble_score])\n",
    "    \n",
    "    # print(\"Baseline score:\", baseline_score)\n",
    "    # print(\"Ensemble score:\", ensemble_score)\n",
    "    # test_df[~test_df[\"image_gt\"].isna()][[\"timestamp\",\"image_gt\", \"image_pred\", \"goes16_pred\", \"goes17_pred\", \"final_pred\", \"type\", \"WFABBA_GOES16_Code\", \"WFABBA_GOES17_Code\"]]\\\n",
    "    #     .to_csv(sliding_window_data_dir + camera + csv_suffix)\n",
    "    test_df[~test_df[\"image_gt\"].isna()]\\\n",
    "        .to_csv(sliding_window_data_dir + camera + csv_suffix)\n",
    "    # print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32260380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('smokey')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "afe615d3e7b8e36a1b63b69c45193ee0f50b2887d76ad336f7f33d5b9a253dea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
